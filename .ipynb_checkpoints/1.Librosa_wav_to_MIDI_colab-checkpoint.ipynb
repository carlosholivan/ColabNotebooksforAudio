{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/carlosholivan/ColabNotebooksforAudio/blob/master/1.Librosa_wav_to_MIDI_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WVmMYF7q0eyA"
   },
   "source": [
    "<img src=\"https://www.unizar.es/sites/default/files/identidadCorporativa/imagen/logoUZ.png\"  width=\"480\">\n",
    "\n",
    "# <a name=\"top\"></a>WAV TO MIDI ISOLATED VOICE (07/05/2020)\n",
    "\n",
    "\n",
    "Authors: Jos√© Ram√≥n Beltr√°n and Carlos Hern√°ndez\n",
    "\n",
    "Department of Electronic Engineering and Communications, Universidad de Zaragoza, Calle Mar√≠a de Luna 3, 50018 Zaragoza\n",
    "\n",
    "This notebook transforms a mono wav audio file into a MIDI file with only Librosa library. The majority part of the code is based on Steve Tjoa notebooks for Music information Retrieval: [GitHub](https://github.com/stevetjoa/musicinformationretrieval.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gUhUr2W0kFW"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1. Librosa Onsets Detection and Pitch Estimation](#librosa)\n",
    "    - [1.1. Librosa Onsets Detection](#librosa-onsets)\n",
    "    - [1.2. Librosa Pitch Estimation](#librosa-pitch)\n",
    "    - [1.3. MIDI Writing](#librosa-midi)\n",
    "    - [1.4. Results](#librosa-results)\n",
    "    - [1.5. Conclusions and Future Work](#librosa-conclusions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IW9USPmg0sGM"
   },
   "source": [
    "## INSTALLING DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "H5N_Cwd71WoF"
   },
   "outputs": [],
   "source": [
    "#@title Install MIDIUtil\n",
    "!pip install MIDIUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Wx4Y-f0TCDNR"
   },
   "outputs": [],
   "source": [
    "#@title Install Librosa\n",
    "\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "jTtJYqng4D9H"
   },
   "outputs": [],
   "source": [
    "#@title Install Google Magenta\n",
    "\n",
    "#@test {\"output\": \"ignore\"}\n",
    "%tensorflow_version 1.x\n",
    "\n",
    "print('Installing dependencies...')\n",
    "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
    "!pip install -qU pyfluidsynth pretty_midi\n",
    "\n",
    "!pip install -qU magenta\n",
    "\n",
    "# Hack to allow python to pick up the newly-installed fluidsynth lib. \n",
    "# This is only needed for the hosted Colab environment.\n",
    "import ctypes.util\n",
    "orig_ctypes_util_find_library = ctypes.util.find_library\n",
    "def proxy_find_library(lib):\n",
    "  if lib == 'fluidsynth':\n",
    "    return 'libfluidsynth.so.1'\n",
    "  else:\n",
    "    return orig_ctypes_util_find_library(lib)\n",
    "ctypes.util.find_library = proxy_find_library\n",
    "\n",
    "print('Importing libraries and defining some helper functions...')\n",
    "from google.colab import files\n",
    "\n",
    "import magenta.music as mm\n",
    "import magenta\n",
    "import tensorflow\n",
    "\n",
    "print('üéâ Done!')\n",
    "print(magenta.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-FwNOHUk0pnc"
   },
   "source": [
    "<img src=\"https://4.bp.blogspot.com/-WELZsAfX1U0/Vl7UxvJNHdI/AAAAAAAAF34/9Kl1x1y0Uv4/s1600/separador.png\" style=\"width:500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "bc8jCsbL1xun"
   },
   "outputs": [],
   "source": [
    "#@title Upload Audio File (wav)\n",
    "import os\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "for name, data in uploaded.items():\n",
    "  with open(name, 'wb') as f:\n",
    "    f.write(data)\n",
    "    #os.rename(f.name, 'file.wav')\n",
    "    song = f.name[:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gof2Bmt1NNQ"
   },
   "source": [
    "# <a name=\"librosa\"></a>1. LIBROSA ONSETS DETECTION AND PITCH ESTIMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0p7QWR0j1QSI"
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import numpy, scipy, IPython.display as ipd, matplotlib.pyplot as plt\n",
    "import librosa, librosa.display\n",
    "from midiutil import MIDIFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpuSMP182fPz"
   },
   "source": [
    "## <a name=\"librosa-onsets\"></a>1.1. LIBROSA ONSETS DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jS17blJ02i7E"
   },
   "outputs": [],
   "source": [
    "wav = song + '.wav'\n",
    "x, sr = librosa.load(wav)\n",
    "\n",
    "bins_per_octave = 36\n",
    "\n",
    "hop_length = 250\n",
    "onset_env = librosa.onset.onset_strength(x, sr=sr, hop_length=hop_length)\n",
    "\n",
    "onset_samples = librosa.onset.onset_detect(x,\n",
    "                                           sr=sr, units='samples', \n",
    "                                           hop_length=hop_length, \n",
    "                                           backtrack=False,\n",
    "                                           pre_max=20,\n",
    "                                           post_max=20,\n",
    "                                           pre_avg=100,\n",
    "                                           post_avg=100,\n",
    "                                           delta=0.2,\n",
    "                                           wait=0)\n",
    "onset_boundaries = numpy.concatenate([[0], onset_samples, [len(x)]])\n",
    "onset_times = librosa.samples_to_time(onset_boundaries, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9hIw7ro13MiP"
   },
   "source": [
    "## <a name=\"librosa-pitch\"></a>1.2. LIBROSA PITCH ESTIMATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4QsI47363Xxx"
   },
   "source": [
    "Librosa pitch estimation is done with the autocorrelation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YikH0-Ex3aLk"
   },
   "outputs": [],
   "source": [
    "def estimate_freq(segment, sr, fmin=50.0, fmax=2000.0):\n",
    "    \n",
    "    # Compute autocorrelation of input segment.\n",
    "    r = librosa.autocorrelate(segment)\n",
    "    \n",
    "    # Define lower and upper limits for the autocorrelation argmax.\n",
    "    i_min = sr/fmax\n",
    "    i_max = sr/fmin\n",
    "    r[:int(i_min)] = 0\n",
    "    r[int(i_max):] = 0\n",
    "    \n",
    "    # Find the location of the maximum autocorrelation.\n",
    "    i = r.argmax()\n",
    "    f0 = float(sr)/i\n",
    "    return f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RAnzCzK3ciN"
   },
   "outputs": [],
   "source": [
    "def estimate_pitch(x, onset_samples, i, sr):\n",
    "    n0 = onset_samples[i]\n",
    "    n1 = onset_samples[i+1]\n",
    "    f0 = estimate_freq(x[n0:n1], sr) \n",
    "    m = 12*(numpy.log2(f0) - numpy.log2(440.0)) + 69 #MIDI number\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKT5pO3H3ekz"
   },
   "outputs": [],
   "source": [
    "signal = []\n",
    "for i in range(len(onset_boundaries)-1):\n",
    "    y = estimate_pitch(x, onset_boundaries, i, sr=sr)\n",
    "    signal.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIWJJubv3hns"
   },
   "source": [
    "## <a name=\"librosa-midi\"></a>1.3. MIDI WRITING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "orglZ3PY3kVM"
   },
   "outputs": [],
   "source": [
    "\"---------------------------write MIDIfile------------------------------\"\n",
    "# create your MIDI object\n",
    "mf = MIDIFile(numTracks = 1)     # only 1 track\n",
    "track = 0   # the only track\n",
    "\n",
    "time_lib = 0    # start at the beginning\n",
    "bpm = 110\n",
    "mf.addTrackName(track, time_lib, \"Sample Track\")\n",
    "mf.addTempo(track, time_lib, bpm)\n",
    "ms_in_1beat = 60000/bpm\n",
    "\n",
    "# add some notes\n",
    "channel = 0\n",
    "volume = 100\n",
    "\n",
    "for i in range(len(onset_times)-1):\n",
    "    pitch = int(numpy.round(signal[i]))     # C4 (middle C)\n",
    "    time_lib = onset_times[i]*1000 / ms_in_1beat          # start on beat 0\n",
    "    duration = (onset_times[i+1]-onset_times[i])*1000 / ms_in_1beat        \n",
    "    mf.addNote(track, channel, pitch, time_lib, duration, volume)\n",
    "    \n",
    "# write it to disk\n",
    "with open('Librosa_' + song + '.mid', 'wb') as outf:\n",
    "    mf.writeFile(outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "No321tRU30L-"
   },
   "source": [
    "## <a name=\"librosa-results\"></a>1.4. LIBROSA RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KAwSXEIz32cw"
   },
   "outputs": [],
   "source": [
    "#General function to plot piano-roll representation + midi and wav comparation\n",
    "import bokeh \n",
    "import magenta.music as mm\n",
    "\n",
    "def midi_pianoroll(file):\n",
    "    print(file)\n",
    "\n",
    "    note_seq = mm.midi_file_to_sequence_proto(file)\n",
    "\n",
    "    # This is a colab utility method that visualizes a NoteSequence.\n",
    "    fig = mm.plot_sequence(note_seq, show_figure=False)\n",
    "    bokeh.plotting.output_notebook()\n",
    "    bokeh.plotting.show(fig)\n",
    "\n",
    "    # This is a colab utility method that plays a NoteSequence.\n",
    "    mm.play_sequence(note_seq,synth=mm.fluidsynth)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "agIz88mP4jzz"
   },
   "outputs": [],
   "source": [
    "#original song\n",
    "print('Orininal song wav')\n",
    "ipd.Audio(song + '.wav', rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlbeQy4u4pgv"
   },
   "outputs": [],
   "source": [
    "\"-------------------MIDI-------------------------\"\n",
    "#MIDI file from librosa\n",
    "file = 'Librosa_' + song + '.mid'\n",
    "midi_pianoroll(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "nBVYjyAmad_M"
   },
   "outputs": [],
   "source": [
    "#@title Download Librosa MIDI File (optional)\n",
    "\n",
    "files.download('Librosa_' + song + '.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvG2wCzAVNf9"
   },
   "source": [
    "## <a name=\"librosa-conclusions\"></a>1.5. CONCLUSIONS AND FUTURE WORK\n",
    "\n",
    "* No silence removal -> Remove silences  \n",
    "* Onsets are not accurate with some voice effects -> Try other libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9NL829zUngU"
   },
   "source": [
    "## <a name=\"librosa-conclusions\"></a>REFERENCES\n",
    "\n",
    "https://musicinformationretrieval.com/pitch_transcription_exercise.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wC_0_W0VX0w"
   },
   "source": [
    "<img src=\"https://4.bp.blogspot.com/-WELZsAfX1U0/Vl7UxvJNHdI/AAAAAAAAF34/9Kl1x1y0Uv4/s1600/separador.png\" style=\"width:500px;\"/>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/2OBjkri2ZpuE0Rj/1hVp",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1.Librosa_wav_to_MIDI_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
