{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.CREPE_onsets_wav_to_MIDI_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tMFVrv73RDsT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosholivan/ColabNotebooksforAudio/blob/master/2_CREPE_onsets_wav_to_MIDI_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bXHg8Z0Fx2su"
      },
      "source": [
        "<img src=\"https://www.unizar.es/sites/default/files/identidadCorporativa/imagen/logoUZ.png\"  width=\"480\">\n",
        "\n",
        "# <a name=\"top\"></a>WAV TO MIDI ISOLATED VOICE (05/2020)\n",
        "\n",
        "\n",
        "Authors: Jos√© Ram√≥n Beltr√°n and Carlos Hern√°ndez\n",
        "\n",
        "Department of Electronic Engineering and Communications, Universidad de Zaragoza, Calle Mar√≠a de Luna 3, 50018 Zaragoza\n",
        "\n",
        "This notebook transforms a mono wav audio file into a MIDI file processing the pitch curve predicted by CREPE neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n_TSgDsERDq0"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "- [1. CREPE Onsets Detection and Pitch Processing](#crepe)\n",
        "    - [1.1. Onsets Detection](#onsets)\n",
        "        - [1.1.1. Crepe Pitch Extraction](#crepe-pitch)\n",
        "        - [1.1.2. Processing Crepe Pitch Curve Estimation](#estimation)\n",
        "        - [1.1.3. Librosa Onsets Detection vs CREPE Onsets Detection from Pitch Curve](#librosa)\n",
        "    - [1.2. Crepe Pitch Processing](#crepe-processing)\n",
        "    - [1.3. MIDI Writing](#midi)\n",
        "    - [1.4. Results](#results)\n",
        "    - [1.5. Conclusions and Future Work](#crepe-conclusions)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kgfzWrSHoC4b"
      },
      "source": [
        "## INSTALLING DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "jc4B7I9boFfg",
        "colab": {}
      },
      "source": [
        "#@title Install MIDIUtil\n",
        "!pip install MIDIUtil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "YJPRnRnDoF4D",
        "colab": {}
      },
      "source": [
        "#@title Install Librosa\n",
        "\n",
        "!pip install librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "mX9w__4WoKxX",
        "colab": {}
      },
      "source": [
        "#@title Install Google Magenta\n",
        "\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "\n",
        "!pip install -qU magenta\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib. \n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "print('Importing libraries and defining some helper functions...')\n",
        "from google.colab import files\n",
        "\n",
        "import magenta.music as mm\n",
        "import magenta\n",
        "import tensorflow\n",
        "\n",
        "print('üéâ Done!')\n",
        "print(magenta.__version__)\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "l13-QfAzsfxP",
        "colab": {}
      },
      "source": [
        "#@title Clone CREPE\n",
        "\n",
        "!git clone https://github.com/marl/crepe.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "4vwtPzCBsjce",
        "colab": {}
      },
      "source": [
        "cd crepe/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "YSmeCLiUsjxf",
        "colab": {}
      },
      "source": [
        "#@title Download CREPE trained models\n",
        "\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "CVyJ3lRBsnUA",
        "colab": {}
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "O4uM8yM-sngS",
        "colab": {}
      },
      "source": [
        "#@title Install Soundfile\n",
        "\n",
        "!pip install SoundFile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "uQJFtD6VvR90",
        "colab": {}
      },
      "source": [
        "#@title Install hmmlearn\n",
        "\n",
        "!pip install git+https://github.com/hmmlearn/hmmlearn.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CulVxXNaRDrV"
      },
      "source": [
        "<img src=\"https://4.bp.blogspot.com/-WELZsAfX1U0/Vl7UxvJNHdI/AAAAAAAAF34/9Kl1x1y0Uv4/s1600/separador.png\" style=\"width:500px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "6Wru4LrGsaEQ",
        "colab": {}
      },
      "source": [
        "#@title Upload Audio File (wav)\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for name, data in uploaded.items():\n",
        "  with open(name, 'wb') as f:\n",
        "    f.write(data)\n",
        "    #os.rename(f.name, 'file.wav')\n",
        "    song = f.name[:-4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PDoI2UiNRDrW"
      },
      "source": [
        "# <a name=\"crepe\"></a>1. CREPE ONSETS DETECION AND PITCH PROCESSING "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4BZMIizJRDrW"
      },
      "source": [
        "Process:\n",
        "* Convert wav to 16bit to process it with CREPE\n",
        "* Pitch extraction with CREPE\n",
        "* Onsets detection with Librosa or CREPE (derivative of the Pitch curve)\n",
        "* Average, mode, most expected value... of the pitch from the current onset to the next one\n",
        "* MIDI or note sequence conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2J-WKEaURDrX",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "from scipy.io import wavfile\n",
        "from collections import Counter\n",
        "import soundfile\n",
        "import os\n",
        "import csv\n",
        "from midiutil import MIDIFile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "\n",
        "import sys\n",
        "sys.path.insert(1, 'crepe/crepe/')\n",
        "import core #this will allow us to run CREPE in the script to not generate a csv file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "86SxcAO-RDre",
        "colab": {}
      },
      "source": [
        "\"-------------------------------------------------------------------------\"\n",
        "\"-----------------------STEP 1: CREATING 16bit WAV FILE-------------------\"\n",
        "\"-------------------------------------------------------------------------\"\n",
        "wav = song + '.wav'\n",
        "\n",
        "#Reading WAV attributes\n",
        "file = soundfile.SoundFile(wav)\n",
        "print('Sample rate: {}'.format(file.samplerate))\n",
        "print('Channels: {}'.format(file.channels))\n",
        "print('Subtype: {}'.format(file.subtype))\n",
        "\n",
        "#Crepe NN works with 16bit wav files so if the imported file is 24bit we\n",
        "#convert it into a 16bit wav file and we export it into another path\n",
        "if file.subtype == 'PCM_24':\n",
        "    data, samplerate = soundfile.read(wav)\n",
        "    soundfile.write('16bitwav_' + song + '.wav', data, samplerate, subtype='PCM_16')\n",
        "    wav_16bit = '16bitwav_' + song + '.wav'\n",
        "else:\n",
        "  wav_16bit = song + '.wav'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fldG1g5YRDrh"
      },
      "source": [
        "## <a name=\"onsets\"></a>1.1. ONSETS  DETECTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dwxrT6R0RDri"
      },
      "source": [
        "### <a name=\"crepe-pitch\"></a>1.1.1. CREPE PITCH EXTRACTION (PREDICTION)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixQ08fy3RDri",
        "colab": {}
      },
      "source": [
        "\"----------------------PITCH ESTIMATION WITH CREPE NN---------------------\"    \n",
        "\"-------------------------STEP 2: CREPE PREDICTION------------------------\"\n",
        "\"-------------------------------------------------------------------------\"\n",
        "\n",
        "sr, audio = wavfile.read(wav_16bit)\n",
        "time, frequency, confidence, activation = core.predict(audio, sr, viterbi=True, step_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1smNAHV3RDrm"
      },
      "source": [
        "Pitch bins in activation curve are calculated as:\n",
        "\\begin{equation}\n",
        "pitchbin = 1200*log_2(\\frac{f}{10})\n",
        "\\end{equation}\n",
        "\n",
        "where 10Hz is the reference frequency.\n",
        "This unitprovides a logarithmic pitch scale where 100 cents equal one semitone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n2-OX-kVRDrm",
        "colab": {}
      },
      "source": [
        "#We can plot the activation curve from CREPE\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.title('Activation curve from CREPE')\n",
        "plt.xlabel('time (ms)')\n",
        "plt.ylabel('Pitch bins')\n",
        "plt.imshow(1-activation.T, origin='lower', cmap='gray')  \n",
        "\n",
        "#We can plot the activation curve from CREPE with frequency an time variables\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Activation curve from CREPE (f0, t)')\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('Fundamental frequency (Hz)')\n",
        "plt.plot(time, frequency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y021EES3RDrq"
      },
      "source": [
        "### <a name=\"estimation\"></a>1.1.2. PROCESSING CREPE PITCH CURVE ESTIMATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SLm2h5sORDrq",
        "colab": {}
      },
      "source": [
        "\"----------------------PITCH ESTIMATION WITH CREPE NN---------------------\"    \n",
        "\"-------------------------STEP 3: CREPE PROCESSING------------------------\"\n",
        "\"-------------------------------------------------------------------------\"\n",
        "#We remove frequencies and time where confidence is lower than 'min_confidence'\n",
        "min_confidence = 0.87\n",
        "#We can plot the activation curve from CREPE without f with a confidence < min_confidence\n",
        "f_clean = [] #list to store frequencies which confidence is >= min_confidence\n",
        "t_clean = [] \n",
        "for i in range(len(frequency)):\n",
        "    if confidence[i] >= min_confidence:\n",
        "        f_clean.append(frequency[i])\n",
        "        t_clean.append(time[i])\n",
        "\n",
        "\n",
        "#The deleted f must be plotted with the real time in the song\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Activation curve from CREPE after removing f0 which confidence < {}'.format(min_confidence))\n",
        "plt.xlabel('time s*100')\n",
        "plt.ylabel('Pitch bins')\n",
        "plt.imshow(1-activation.T, origin='lower', cmap='gray')  \n",
        "#we plot the removed f0 which confidence < min_confidence\n",
        "for j in range(len(confidence)):\n",
        "    if confidence[j] < min_confidence:\n",
        "        plt.axvline(time[j]*100, color='r', linestyle='dotted')\n",
        "        \n",
        "#frequency plot\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Activation curve from CREPE after computing f0 average and delete f0 which confidence < {}'.format(min_confidence))\n",
        "plt.ylabel('Fundamental frequency (Hz)')\n",
        "plt.plot(f_clean)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Activation curve from CREPE after computing f0 average and delete f0 which confidence < {}'.format(min_confidence))\n",
        "plt.ylabel('Fundamental frequency (Hz)')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.plot(t_clean, f_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ETMNlBWORDrt"
      },
      "source": [
        "#### DERIVATIVES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "emo8pe0CRDru"
      },
      "source": [
        "We now compute the 1st and 2nd order derivatives from which we'll extract the onsets.\n",
        "\n",
        "<img src=\"https://i.ytimg.com/vi/3n-z5C30YPE/maxresdefault.jpg\" style=\"width:500px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xl7KzrBQRDru",
        "colab": {}
      },
      "source": [
        "\"----------------DERIVATIVES (ONSETs DETECTION)-------------------------\"\n",
        "#1st Derivative\n",
        "derivative = []\n",
        "for i in range(len(f_clean)):\n",
        "    derivative = np.diff(f_clean)\n",
        "     \n",
        "#2nd Derivative\n",
        "sec_derivative = []\n",
        "for i in range(len(derivative)):\n",
        "    sec_derivative = np.diff(derivative)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G00dkfNLRDrx",
        "colab": {}
      },
      "source": [
        "#Plotting the 1st order derivative\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('1st order Derivative of the Pitch curve after removing f0 which confidence < {}'.format(min_confidence))\n",
        "plt.plot(derivative)\n",
        "\n",
        "#Plotting the 2nd order derivative\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('2nd order Derivative of the Pitch curve after removing f0 which confidence < {}'.format(min_confidence))\n",
        "plt.plot(sec_derivative)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DtvzzITuRDr0"
      },
      "source": [
        "#### EXTRACTING ONSETS FROM DERIVATIONVES OF THE PITCH CURVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jTAM3hN4RDr0",
        "colab": {}
      },
      "source": [
        "\"----------------ONSETs DETECTION from DERIVATIVES-------------------------\"\n",
        "#We can extract the onsets from the 1st order derivative of the pitch curve\n",
        "first_der = []\n",
        "onset_times_first_der = []\n",
        "limit = 2\n",
        "for i in range(len(derivative)):\n",
        "    if (derivative[i] - derivative[i-1]) > limit or (derivative[i-1] - derivative[i]) > limit:\n",
        "        first_der.append(i)\n",
        "        onset_times_first_der.append(t_clean[i]) \n",
        "\n",
        "#We can extract the onsets from the 2nd order derivative of the pitch curve\n",
        "sec_der = []\n",
        "onset_times_sec_der = []\n",
        "limit = 2\n",
        "for i in range(len(sec_derivative)):\n",
        "    if (sec_derivative[i] - sec_derivative[i-1]) > limit or (sec_derivative[i-1] - sec_derivative[i]) > limit:\n",
        "        sec_der.append(i)\n",
        "        onset_times_sec_der.append(t_clean[i]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o4QI0ka_RDr3",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('1st order Derivative with onsets detection')\n",
        "plt.plot(derivative)\n",
        "for onset_crepe in first_der:\n",
        "    plt.axvline(onset_crepe, color='magenta', linestyle='dotted')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('2nd order Derivative with onsets detection')\n",
        "plt.plot(sec_derivative)\n",
        "for onset_crepe in sec_der:\n",
        "    plt.axvline(onset_crepe, color='magenta', linestyle='dotted')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lL8Fkm1RRDr6"
      },
      "source": [
        "Table of bpm with notes duration in sec: http://www.sengpielaudio.com/calculator-bpmtempotime.htm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ELvT7u95RDr6",
        "colab": {}
      },
      "source": [
        "#We clean the onsets by removing onsets which distance between them is less than 'lim'\n",
        "lim = 0.08 #sec (a 1/16 note at 180bpm is 0.084sec so we won't loose so much information setting the limit to 0.08s)\n",
        "onset_times_first_der_clean = []\n",
        "for i in range(len(onset_times_first_der)):\n",
        "    if (onset_times_first_der[i] - onset_times_first_der[i-1]) > lim or i == 0 or i == len(onset_times_first_der):\n",
        "        onset_times_first_der_clean.append(onset_times_first_der[i])\n",
        "onset_times_first_der_clean.insert(0,time[0])\n",
        "onset_times_first_der_clean.append(time[-1])\n",
        "\n",
        "#We clean the onsets by removing onsets which distance between them is less than 'lim'\n",
        "lim = 0.08 #sec (a 1/16 note at 180bpm is 0.084sec so we won't loose so much information setting the limit to 0.2s)\n",
        "onset_times_sec_der_clean = []\n",
        "for i in range(len(onset_times_sec_der)):\n",
        "    if (onset_times_sec_der[i] - onset_times_sec_der[i-1]) > lim or i == 0 or i == len(onset_times_sec_der):\n",
        "        onset_times_sec_der_clean.append(onset_times_sec_der[i])\n",
        "onset_times_sec_der_clean.insert(0,time[0])\n",
        "onset_times_sec_der_clean.append(time[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i0tMQbvqRDr_"
      },
      "source": [
        "### <a name=\"librosa\"></a>1.1.3. LIBROSA ONSETS DETECTION vs CREPE ONSETS DETECTION FROM PITCH CURVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fb5C8Xeew8xu",
        "colab": {}
      },
      "source": [
        "x, sr = librosa.load(wav_16bit)\n",
        "\n",
        "hop_length = 250\n",
        "onset_env = librosa.onset.onset_strength(x, sr=sr, hop_length=hop_length)\n",
        "\n",
        "onset_samples = librosa.onset.onset_detect(x,\n",
        "                                           sr=sr, units='samples', \n",
        "                                           hop_length=hop_length, \n",
        "                                           backtrack=False,\n",
        "                                           pre_max=20,\n",
        "                                           post_max=20,\n",
        "                                           pre_avg=100,\n",
        "                                           post_avg=100,\n",
        "                                           delta=0.2,\n",
        "                                           wait=0)\n",
        "onset_boundaries = np.concatenate([[0], onset_samples, [len(x)]])\n",
        "onset_times = librosa.samples_to_time(onset_boundaries, sr=sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJ0gMiPHRDsA",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('CREPE onsets detection from 1st order derivative')\n",
        "plt.xlabel('time (ms)')\n",
        "plt.ylabel('Pitch bins')\n",
        "plt.imshow(1-activation.T, origin='lower', cmap='gray') \n",
        "for onset_crepe in onset_times_first_der_clean:\n",
        "    plt.axvline(onset_crepe*100, color='magenta', linestyle='dotted')\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('CREPE onsets detection from 2nd order derivative')\n",
        "plt.xlabel('time (ms)')\n",
        "plt.ylabel('Pitch bins')\n",
        "plt.imshow(1-activation.T, origin='lower', cmap='gray') \n",
        "for onset_crepe in onset_times_sec_der_clean:\n",
        "    plt.axvline(onset_crepe*100, color='magenta', linestyle='dotted')\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Librosa onsets detection')\n",
        "plt.xlabel('time (ms)')\n",
        "plt.ylabel('Pitch bins')\n",
        "plt.imshow(1-activation.T, origin='lower', cmap='gray') \n",
        "for onset_crepe in onset_times:\n",
        "    plt.axvline(onset_crepe*100, color='BLUE', linestyle='dotted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-HhOYwn5RDsD",
        "colab": {}
      },
      "source": [
        "#Example of why we need to compute the weighted average and not just an average\n",
        "f_clean_int = [int(round(i)) for i in f_clean] #convert f to integers\n",
        "\n",
        "limit = np.searchsorted(t_clean, onset_times_first_der_clean[1])\n",
        "upper_limit = np.searchsorted(t_clean, onset_times_first_der_clean[2])\n",
        "\n",
        "#The average is\n",
        "av = np.mean(f_clean_int[limit:upper_limit])\n",
        "print( \"The average of f in the interval\", '[',limit,',', upper_limit,'] ms', \"is : \", av)\n",
        "\n",
        "#The mode is\n",
        "data = Counter(f_clean_int[limit:upper_limit])   # Returns all unique items and their counts\n",
        "data.most_common(1)[0][0]  # Returns the highest occurring item\n",
        "print(\"The mode (most repeated f) is :\", data.most_common(1)[0][0],'which is repeated', data.most_common(1)[0][1],'times')\n",
        "\n",
        "mode_ex = data.most_common() #mode.most_common() is a list of tuples [element, repetitions]\n",
        "f_ex, count_ex = zip(*mode_ex) #we split the list of tuples in 2 lists, one will store the value of f and the other the repetitions of each f\n",
        "\n",
        "mean_ex = np.average(f_ex, weights=count_ex)\n",
        "print(\"The weighted average is :\", mean_ex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ivd_0oqbRDsF"
      },
      "source": [
        "## <a name=\"crepe-processing\"></a>1.2. CREPE PITCH PROCESSING "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2LDbUIx4RDsG"
      },
      "source": [
        "Once we have a good estimation of the onsets, we can continue with adjusting the pitch between onsets intervals\n",
        "\n",
        "(colors for matplotlib plots: https://i.stack.imgur.com/nCk6u.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HQOgwY6HRDsH",
        "colab": {}
      },
      "source": [
        "\"-------------------------------------------------------------------------\"\n",
        "\"------------------STEP 4: PROCESS CREPE PITCH EXTRACTION-----------------\"\n",
        "\"-------------------------------------------------------------------------\"\n",
        "#We will write just one f for each onset interval. This pitch will be the weigthed average mean. \n",
        "#The average will be set depending on how many times does each pitch is repeated in the interval, so the more repeated\n",
        "#pitches will be a higher weigth to compute the mean\n",
        "\n",
        "mean_list = []\n",
        "for onset in range(len(onset_times_first_der_clean)-1):\n",
        "    limit = np.searchsorted(t_clean, onset_times_first_der_clean[onset])\n",
        "    upper_limit = np.searchsorted(t_clean, onset_times_first_der_clean[onset+1])\n",
        "    if limit != upper_limit:\n",
        "        mode = Counter(f_clean_int[limit:upper_limit])\n",
        "        mode_list = mode.most_common() #mode.most_common() is a list of tuples [element, repetitions]\n",
        "        f_list, count_list = zip(*mode_list) #we split the list of tuples in 2 lists, one will store the value of f and the other the repetitions of each f\n",
        "        if len(set(count_list)) == 1: #il all f in the onsets interval have the same repetitions\n",
        "            mean = np.mean(f_list) #we take the average f value in the onsets interval\n",
        "        else:\n",
        "            mean = f_list[0] #mode in the onsets interval\n",
        "        mean_list.append(mean)  \n",
        "    else:\n",
        "        mean_list.append(0.01) #not 0 because later we'll compute a logarithm so setting 0.01 we'll avoid inf values\n",
        "mean_list = [int(i) for i in mean_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NDnKJKXVRDsJ",
        "colab": {}
      },
      "source": [
        "#We can plot the initial activation pitch curve from crepe with the obtained mean after all the previous processing\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Raw pitch prediction curve with final processed pitches')\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('Fundamental frequency f0 (Hz)')\n",
        "plt.plot(time, frequency) \n",
        "for onset_crepe in range(len(onset_times_first_der_clean)-1):\n",
        "    plt.axvline(onset_times_first_der_clean[onset_crepe], color='magenta', linestyle='dotted')\n",
        "    plt.hlines(y=mean_list[onset_crepe],\n",
        "                        xmin=onset_times_first_der_clean[onset_crepe], \n",
        "                        xmax=onset_times_first_der_clean[onset_crepe+1], color='yellow')\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('CREPE onsets detection from 1st order derivative')\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('Fundamental frequency f0 (Hz)')\n",
        "plt.plot(t_clean, f_clean) \n",
        "for onset_crepe in range(len(onset_times_first_der_clean)-1):\n",
        "    plt.axvline(onset_times_first_der_clean[onset_crepe], color='magenta', linestyle='dotted')\n",
        "    plt.hlines(y=mean_list[onset_crepe],\n",
        "                        xmin=onset_times_first_der_clean[onset_crepe], \n",
        "                        xmax=onset_times_first_der_clean[onset_crepe+1], color='yellow')\n",
        "    \n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Predicted frequencies')\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('Fundamental frequency f0 (Hz)')\n",
        "for onset_crepe in range(len(onset_times_first_der_clean)-1):\n",
        "    plt.hlines(y=mean_list[onset_crepe],\n",
        "                        xmin=onset_times_first_der_clean[onset_crepe], \n",
        "                        xmax=onset_times_first_der_clean[onset_crepe+1], color='yellow')\n",
        "\n",
        "midi_notes_list = [12*(np.log2(i) - np.log2(440.0)) + 69 for i in mean_list] \n",
        "plt.style.use('dark_background')\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Predicted Pitch: Pianoroll Representation')\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('Pitch')\n",
        "for onset_crepe in range(len(onset_times_first_der_clean)-1):\n",
        "    plt.hlines(y=midi_notes_list[onset_crepe],\n",
        "                        xmin=onset_times_first_der_clean[onset_crepe], \n",
        "                        xmax=onset_times_first_der_clean[onset_crepe+1], color='#8cffdb', linewidth=7.0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ReoLQ__cRDsM"
      },
      "source": [
        "## <a name=\"midi\"></a>1.3. MIDI WRITING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2M-b-0vVRDsP"
      },
      "source": [
        "We now have to convert the frequencies to MIDI notes\n",
        "\n",
        "The way to convert f0 to a MIDI note is:\n",
        "\\begin{equation}\n",
        "MIDInote = 12*(log_2(f) - log_2(440)) + 69 \n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d8G8j3JXRDsP"
      },
      "source": [
        "<img src=\"https://i.pinimg.com/originals/fe/13/eb/fe13ebb344f12175dca1b0a63617bf73.gif\" style=\"width:500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1ToT_6BVKa7H"
      },
      "source": [
        "We'll write 3 MIDI files:\n",
        "* 1. CREPE_raw: MIDI file written directly from CREPE pitch curve\n",
        "* 2. CREPE_raw_clean: MIDI file written after removing frequencies which conficence < 0.87\n",
        "* 3. CREPE: MIDI file after pitch processing which has been done in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aqPr2wYzKKJU",
        "colab": {}
      },
      "source": [
        "\"-------------------------------------------------------------------------\"\n",
        "\"------------------STEP 5: RAW CREPE PITCH CURVE TO MIDI------------------\"\n",
        "\"-------------------------------------------------------------------------\"    \n",
        "midi_notes_list_raw = [12*(np.log2(i) - np.log2(440.0)) + 69 for i in frequency] \n",
        "\n",
        "# create your MIDI object\n",
        "mf_raw = MIDIFile(numTracks = 1)     # only 1 track\n",
        "track_raw = 0   # the only track\n",
        "\n",
        "time_note_raw = 0    # start at the beginning\n",
        "bpm = 110\n",
        "mf_raw.addTrackName(track_raw, time_note_raw, \"Sample Track\")\n",
        "mf_raw.addTempo(track_raw, time_note_raw, bpm)\n",
        "ms_in_1beat = 60000/bpm\n",
        "\n",
        "# add some notes\n",
        "channel_raw = 0\n",
        "volume_raw = 100\n",
        "\n",
        "for i in range(len(frequency)-1):\n",
        "    pitch = int(round(midi_notes_list_raw[i])) #write MIDi note     \n",
        "    time_note = time[i]*1000 / ms_in_1beat          # start on beat 0\n",
        "    duration = (time[i+1]-time[i])*1000 / ms_in_1beat        # 1 beat long\n",
        "    mf_raw.addNote(track_raw, channel_raw, pitch, time_note, duration, volume_raw)\n",
        "    \n",
        "# write it to disk\n",
        "with open('CREPE_raw_' + song + '.mid', 'wb') as outf:\n",
        "    mf_raw.writeFile(outf)\n",
        "\n",
        "print(\"CREPE MIDI file has been created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "To3MElqzKKXX",
        "colab": {}
      },
      "source": [
        "\"-------------------------------------------------------------------------\"\n",
        "\"-------STEP 5: CREPE PITCH CURVE TO MIDI REMOVING <0.87 CONFIDENCE-------\"\n",
        "\"-------------------------------------------------------------------------\"    \n",
        "midi_notes_list_clean = [12*(np.log2(i) - np.log2(440.0)) + 69 for i in f_clean] \n",
        "\n",
        "# create your MIDI object\n",
        "mf_raw_clean = MIDIFile(numTracks = 1)     # only 1 track\n",
        "track_raw = 0   # the only track\n",
        "\n",
        "time_note_raw = 0    # start at the beginning\n",
        "bpm = 110\n",
        "mf_raw_clean.addTrackName(track_raw, time_note_raw, \"Sample Track\")\n",
        "mf_raw_clean.addTempo(track_raw, time_note_raw, bpm)\n",
        "ms_in_1beat = 60000/bpm\n",
        "\n",
        "# add some notes\n",
        "channel_raw = 0\n",
        "volume_raw = 100\n",
        "\n",
        "for i in range(len(t_clean)-1):\n",
        "    pitch = int(round(midi_notes_list_clean[i])) #write MIDi note     \n",
        "    time_note = t_clean[i]*1000 / ms_in_1beat          # start on beat 0\n",
        "    duration = (t_clean[i+1]-t_clean[i])*1000 / ms_in_1beat        # 1 beat long\n",
        "    mf_raw_clean.addNote(track_raw, channel_raw, pitch, time_note, duration, volume_raw)\n",
        "    \n",
        "# write it to disk\n",
        "with open('CREPE_raw_clean_' + song + '.mid', 'wb') as outf:\n",
        "    mf_raw_clean.writeFile(outf)\n",
        "\n",
        "print(\"CREPE MIDI file has been created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wwiFwKzALNeR",
        "colab": {}
      },
      "source": [
        "\"-------------------------------------------------------------------------\"\n",
        "\"------------STEP 5: CONVERT CREPE PITCH PREDICTION TO MIDI---------------\"\n",
        "\"-------------------------------------------------------------------------\"    \n",
        "midi_notes_list = []\n",
        "for i in mean_list:\n",
        "    if i == 0:\n",
        "        midi_notes = 0\n",
        "    else:\n",
        "        midi_notes = 12*(np.log2(i) - np.log2(440.0)) + 69\n",
        "    midi_notes_list.append(midi_notes)\n",
        "\n",
        "# create your MIDI object\n",
        "mf = MIDIFile(numTracks = 1)     # only 1 track\n",
        "track = 0   # the only track\n",
        "\n",
        "time_note = 0    # start at the beginning\n",
        "bpm = 110\n",
        "mf.addTrackName(track, time_note, \"Sample Track\")\n",
        "mf.addTempo(track, time_note, bpm)\n",
        "ms_in_1beat = 60000/bpm\n",
        "\n",
        "# add some notes\n",
        "channel = 0\n",
        "volume = 100\n",
        "\n",
        "for i in range(len(onset_times_first_der_clean)-1):\n",
        "    pitch = int(round(midi_notes_list[i])) #write MIDi note     \n",
        "    time_note = onset_times_first_der_clean[i]*1000 / ms_in_1beat          # start on beat 0\n",
        "    duration = (onset_times_first_der_clean[i+1]-onset_times_first_der_clean[i])*1000 / ms_in_1beat        # 1 beat long\n",
        "    mf.addNote(track, channel, pitch, time_note, duration, volume)\n",
        "    \n",
        "# write it to disk\n",
        "with open('CREPE_onsets_' + song + '.mid', 'wb') as outf:\n",
        "    mf.writeFile(outf)\n",
        "\n",
        "print(\"CREPE MIDI file has been created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tMFVrv73RDsT"
      },
      "source": [
        "## <a name=\"results\"></a>1.4. RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "el7Br23OK9G6"
      },
      "source": [
        "And now we just play the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MquR3cgqPJu1",
        "colab": {}
      },
      "source": [
        "#General function to plot piano-roll representation + midi and wav comparation\n",
        "import bokeh \n",
        "import magenta.music as mm\n",
        "\n",
        "def midi_pianoroll(file):\n",
        "    print(file)\n",
        "\n",
        "    note_seq = mm.midi_file_to_sequence_proto(file)\n",
        "\n",
        "    # This is a colab utility method that visualizes a NoteSequence.\n",
        "    fig = mm.plot_sequence(note_seq, show_figure=False)\n",
        "    bokeh.plotting.output_notebook()\n",
        "    bokeh.plotting.show(fig)\n",
        "\n",
        "    # This is a colab utility method that plays a NoteSequence.\n",
        "    mm.play_sequence(note_seq,synth=mm.fluidsynth)\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QkcNX_9lRDsU",
        "colab": {}
      },
      "source": [
        "#original song\n",
        "ipd.Audio(wav_16bit, rate=sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PXAxANW2K3I3",
        "colab": {}
      },
      "source": [
        "\"-------------------MIDI-------------------------\"\n",
        "#MIDI file from raw pitch curve\n",
        "file = 'CREPE_raw_' + song + '.mid'\n",
        "midi_pianoroll(file)\n",
        "\n",
        "\"-------------------MIDI-------------------------\"\n",
        "#MIDI file from raw pitch curve\n",
        "file = 'CREPE_raw_clean_' + song + '.mid'\n",
        "midi_pianoroll(file)\n",
        "\n",
        "\"-------------------MIDI-------------------------\"\n",
        "#MIDI file after processing\n",
        "file = 'CREPE_' + song + '.mid'\n",
        "midi_pianoroll(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_G37vIdELtVV",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Pianoroll Representation: raw pitch from CREPE')\n",
        "plt.grid(axis='y', linewidth=0.3)\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('Pitch')\n",
        "for o in range(len(time)-1):\n",
        "    plt.hlines(y=midi_notes_list_raw[o],\n",
        "                        xmin=time[o], \n",
        "                        xmax=time[o+1], color='#EEFF42', linewidth=7.0)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Pianoroll Representation: pitch after removing f which confidence < 0.87')\n",
        "plt.grid(axis='y', linewidth=0.3)\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('Pitch')\n",
        "for o in range(len(t_clean)-1):\n",
        "    plt.hlines(y=midi_notes_list_clean[o],\n",
        "                        xmin=t_clean[o], \n",
        "                        xmax=t_clean[o+1], color='#FF0000', linewidth=7.0)\n",
        "    \n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Pianoroll Representation: Processed pitch')\n",
        "plt.grid(axis='y', linewidth=0.3)\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('Pitch')\n",
        "for onset_crepe in range(len(onset_times_first_der_clean)-1):\n",
        "    plt.hlines(y=midi_notes_list[onset_crepe],\n",
        "                        xmin=onset_times_first_der_clean[onset_crepe], \n",
        "                        xmax=onset_times_first_der_clean[onset_crepe+1], color='#8cffdb', linewidth=7.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kRAEJ_SxLyY5",
        "colab": {}
      },
      "source": [
        "#plotting all together\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.title('Pianoroll Representation: Processed pitch')\n",
        "plt.grid(axis='y', linewidth=0.3)\n",
        "plt.xlabel('time (s)')\n",
        "plt.ylabel('Pitch')\n",
        "\n",
        "for o in range(len(time)-1):\n",
        "    plt.hlines(y=midi_notes_list_raw[o],\n",
        "                        xmin=time[o], \n",
        "                        xmax=time[o+1], color='#EEFF42', linewidth=7.0)\n",
        "\n",
        "for o in range(len(t_clean)-1):\n",
        "    plt.hlines(y=midi_notes_list_clean[o],\n",
        "                        xmin=t_clean[o], \n",
        "                        xmax=t_clean[o+1], color='#FF0000', linewidth=7.0)\n",
        "\n",
        "for onset_crepe in range(len(onset_times_first_der_clean)-1):\n",
        "    plt.hlines(y=midi_notes_list[onset_crepe],\n",
        "                        xmin=onset_times_first_der_clean[onset_crepe], \n",
        "                        xmax=onset_times_first_der_clean[onset_crepe+1], color='#8cffdb', linewidth=7.0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "xCyn0txrKB_Q",
        "colab": {}
      },
      "source": [
        "#@title Download raw MIDI File (optional)\n",
        "\n",
        "files.download('CREPE_raw_' + song + '.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "kP-wZS2mKKGJ",
        "colab": {}
      },
      "source": [
        "#@title Download raw clean MIDI File (optional)\n",
        "\n",
        "files.download('CREPE_raw_clean_' + song + '.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "WSHugQh9KN-4",
        "colab": {}
      },
      "source": [
        "#@title Download Processed MIDI File (optional)\n",
        "\n",
        "files.download('CREPE_onsets_' + song + '.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uaE92RFdRDsZ"
      },
      "source": [
        "## <a name=\"crepe-conclusions\"></a>1.5. CONCLUSIONS AND FUTURE WORK\n",
        "\n",
        "* No silence removal -> Remove silences looking at the removed f0 with less than 0.87 confidence \n",
        "* The limits set in the derivatives to extract the onsets depend on the songs/voice effects -> is onsets detection necessary?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JO9z0VeXRDs0"
      },
      "source": [
        "REFERENCES\n",
        "\n",
        "* https://github.com/marl/crepe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4o8A8v2qAvPc"
      },
      "source": [
        "<a href=\"#top\">Back to top</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q6tzxOMlAlX1"
      },
      "source": [
        "<img src=\"https://4.bp.blogspot.com/-WELZsAfX1U0/Vl7UxvJNHdI/AAAAAAAAF34/9Kl1x1y0Uv4/s1600/separador.png\" style=\"width:500px;\"/>"
      ]
    }
  ]
}