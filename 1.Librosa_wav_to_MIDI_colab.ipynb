{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.Librosa_wav_to_MIDI_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/2OBjkri2ZpuE0Rj/1hVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosholivan/wavmono2midi/blob/master/1.Librosa_wav_to_MIDI_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVmMYF7q0eyA",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://www.clubexcelencia.org/sites/default/files/fotos/images/noticias/visionarios/universidadzaragoza01.jpg)\n",
        "\n",
        "# <a name=\"top\"></a>WAV TO MIDI ISOLATED VOICE (07/05/2020)\n",
        "\n",
        "\n",
        "Authors: Jos√© Ram√≥n Beltr√°n and Carlos Hern√°ndez\n",
        "\n",
        "Department of Electronic Engineering and Communications, Universidad de Zaragoza, Calle Mar√≠a de Luna 3, 50018 Zaragoza\n",
        "\n",
        "This notebook transforms a mono wav audio file into a MIDI file with only Librosa library. The majority part of the code is based on Steve Tjoa notebooks for Music information Retrieval: [GitHub](https://github.com/stevetjoa/musicinformationretrieval.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gUhUr2W0kFW",
        "colab_type": "text"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "- [1. Librosa Onsets Detection and Pitch Estimation](#librosa)\n",
        "    - [1.1. Librosa Onsets Detection](#librosa-onsets)\n",
        "    - [1.2. Librosa Pitch Estimation](#librosa-pitch)\n",
        "    - [1.3. MIDI Writing](#librosa-midi)\n",
        "    - [1.4. Results](#librosa-results)\n",
        "    - [1.5. Conclusions and Future Work](#librosa-conclusions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW9USPmg0sGM",
        "colab_type": "text"
      },
      "source": [
        "## INSTALLING DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5N_Cwd71WoF",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install MIDIUtil\n",
        "!pip install MIDIUtil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx4Y-f0TCDNR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install Librosa\n",
        "\n",
        "!pip install librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTtJYqng4D9H",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install Google Magenta\n",
        "\n",
        "#@test {\"output\": \"ignore\"}\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "\n",
        "!pip install -qU magenta\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib. \n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "print('Importing libraries and defining some helper functions...')\n",
        "from google.colab import files\n",
        "\n",
        "import magenta.music as mm\n",
        "import magenta\n",
        "import tensorflow\n",
        "\n",
        "print('üéâ Done!')\n",
        "print(magenta.__version__)\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FwNOHUk0pnc",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://4.bp.blogspot.com/-WELZsAfX1U0/Vl7UxvJNHdI/AAAAAAAAF34/9Kl1x1y0Uv4/s1600/separador.png\" style=\"width:500px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc8jCsbL1xun",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Upload Audio File (wav)\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for name, data in uploaded.items():\n",
        "  with open(name, 'wb') as f:\n",
        "    f.write(data)\n",
        "    #os.rename(f.name, 'file.wav')\n",
        "    song = f.name[:-4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gof2Bmt1NNQ",
        "colab_type": "text"
      },
      "source": [
        "# <a name=\"librosa\"></a>1. LIBROSA ONSETS DETECTION AND PITCH ESTIMATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p7QWR0j1QSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn\n",
        "import numpy, scipy, IPython.display as ipd, matplotlib.pyplot as plt\n",
        "import librosa, librosa.display\n",
        "from midiutil import MIDIFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpuSMP182fPz",
        "colab_type": "text"
      },
      "source": [
        "## <a name=\"librosa-onsets\"></a>1.1. LIBROSA ONSETS DETECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS17blJ02i7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wav = song + '.wav'\n",
        "x, sr = librosa.load(wav)\n",
        "\n",
        "bins_per_octave = 36\n",
        "\n",
        "hop_length = 250\n",
        "onset_env = librosa.onset.onset_strength(x, sr=sr, hop_length=hop_length)\n",
        "\n",
        "onset_samples = librosa.onset.onset_detect(x,\n",
        "                                           sr=sr, units='samples', \n",
        "                                           hop_length=hop_length, \n",
        "                                           backtrack=False,\n",
        "                                           pre_max=20,\n",
        "                                           post_max=20,\n",
        "                                           pre_avg=100,\n",
        "                                           post_avg=100,\n",
        "                                           delta=0.2,\n",
        "                                           wait=0)\n",
        "onset_boundaries = numpy.concatenate([[0], onset_samples, [len(x)]])\n",
        "onset_times = librosa.samples_to_time(onset_boundaries, sr=sr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hIw7ro13MiP",
        "colab_type": "text"
      },
      "source": [
        "## <a name=\"librosa-pitch\"></a>1.2. LIBROSA PITCH ESTIMATION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QsI47363Xxx",
        "colab_type": "text"
      },
      "source": [
        "Librosa pitch estimation is done with the autocorrelation function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YikH0-Ex3aLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def estimate_freq(segment, sr, fmin=50.0, fmax=2000.0):\n",
        "    \n",
        "    # Compute autocorrelation of input segment.\n",
        "    r = librosa.autocorrelate(segment)\n",
        "    \n",
        "    # Define lower and upper limits for the autocorrelation argmax.\n",
        "    i_min = sr/fmax\n",
        "    i_max = sr/fmin\n",
        "    r[:int(i_min)] = 0\n",
        "    r[int(i_max):] = 0\n",
        "    \n",
        "    # Find the location of the maximum autocorrelation.\n",
        "    i = r.argmax()\n",
        "    f0 = float(sr)/i\n",
        "    return f0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RAnzCzK3ciN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def estimate_pitch(x, onset_samples, i, sr):\n",
        "    n0 = onset_samples[i]\n",
        "    n1 = onset_samples[i+1]\n",
        "    f0 = estimate_freq(x[n0:n1], sr) \n",
        "    m = 12*(numpy.log2(f0) - numpy.log2(440.0)) + 69 #MIDI number\n",
        "    return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKT5pO3H3ekz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signal = []\n",
        "for i in range(len(onset_boundaries)-1):\n",
        "    y = estimate_pitch(x, onset_boundaries, i, sr=sr)\n",
        "    signal.append(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIWJJubv3hns",
        "colab_type": "text"
      },
      "source": [
        "## <a name=\"librosa-midi\"></a>1.3. MIDI WRITING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orglZ3PY3kVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"---------------------------write MIDIfile------------------------------\"\n",
        "# create your MIDI object\n",
        "mf = MIDIFile(numTracks = 1)     # only 1 track\n",
        "track = 0   # the only track\n",
        "\n",
        "time_lib = 0    # start at the beginning\n",
        "bpm = 110\n",
        "mf.addTrackName(track, time_lib, \"Sample Track\")\n",
        "mf.addTempo(track, time_lib, bpm)\n",
        "ms_in_1beat = 60000/bpm\n",
        "\n",
        "# add some notes\n",
        "channel = 0\n",
        "volume = 100\n",
        "\n",
        "for i in range(len(onset_times)-1):\n",
        "    pitch = int(numpy.round(signal[i]))     # C4 (middle C)\n",
        "    time_lib = onset_times[i]*1000 / ms_in_1beat          # start on beat 0\n",
        "    duration = (onset_times[i+1]-onset_times[i])*1000 / ms_in_1beat        \n",
        "    mf.addNote(track, channel, pitch, time_lib, duration, volume)\n",
        "    \n",
        "# write it to disk\n",
        "with open('Librosa_' + song + '.mid', 'wb') as outf:\n",
        "    mf.writeFile(outf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No321tRU30L-",
        "colab_type": "text"
      },
      "source": [
        "## <a name=\"librosa-results\"></a>1.4. LIBROSA RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAwSXEIz32cw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#General function to plot piano-roll representation + midi and wav comparation\n",
        "import bokeh \n",
        "import magenta.music as mm\n",
        "\n",
        "def midi_pianoroll(file):\n",
        "    print(file)\n",
        "\n",
        "    note_seq = mm.midi_file_to_sequence_proto(file)\n",
        "\n",
        "    # This is a colab utility method that visualizes a NoteSequence.\n",
        "    fig = mm.plot_sequence(note_seq, show_figure=False)\n",
        "    bokeh.plotting.output_notebook()\n",
        "    bokeh.plotting.show(fig)\n",
        "\n",
        "    # This is a colab utility method that plays a NoteSequence.\n",
        "    mm.play_sequence(note_seq,synth=mm.fluidsynth)\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agIz88mP4jzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#original song\n",
        "print('Orininal song wav')\n",
        "ipd.Audio(song + '.wav', rate=sr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlbeQy4u4pgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"-------------------MIDI-------------------------\"\n",
        "#MIDI file from librosa\n",
        "file = 'Librosa_' + song + '.mid'\n",
        "midi_pianoroll(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBVYjyAmad_M",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Download Librosa MIDI File (optional)\n",
        "\n",
        "files.download('Librosa_' + song + '.mid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvG2wCzAVNf9",
        "colab_type": "text"
      },
      "source": [
        "## <a name=\"librosa-conclusions\"></a>1.5. CONCLUSIONS AND FUTURE WORK\n",
        "\n",
        "* No silence removal -> Remove silences  \n",
        "* Onsets are not accurate with some voice effects -> Try other libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9NL829zUngU",
        "colab_type": "text"
      },
      "source": [
        "## <a name=\"librosa-conclusions\"></a>REFERENCES\n",
        "\n",
        "https://musicinformationretrieval.com/pitch_transcription_exercise.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wC_0_W0VX0w",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://4.bp.blogspot.com/-WELZsAfX1U0/Vl7UxvJNHdI/AAAAAAAAF34/9Kl1x1y0Uv4/s1600/separador.png\" style=\"width:500px;\"/>"
      ]
    }
  ]
}
